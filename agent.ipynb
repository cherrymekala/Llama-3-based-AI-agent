{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting haystack-ai\n",
      "  Downloading haystack_ai-2.3.1-py3-none-any.whl (350 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m350.3/350.3 KB\u001b[0m \u001b[31m289.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting openai>=1.1.0\n",
      "  Downloading openai-1.40.2-py3-none-any.whl (360 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m360.7/360.7 KB\u001b[0m \u001b[31m685.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/cherry/.local/lib/python3.10/site-packages (from haystack-ai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/cherry/.local/lib/python3.10/site-packages (from haystack-ai) (4.66.1)\n",
      "Collecting haystack-experimental\n",
      "  Downloading haystack_experimental-0.1.1-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.8/41.8 KB\u001b[0m \u001b[31m299.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from haystack-ai) (8.10.0)\n",
      "Requirement already satisfied: numpy<2 in /home/cherry/.local/lib/python3.10/site-packages (from haystack-ai) (1.26.4)\n",
      "Requirement already satisfied: pyyaml in /home/cherry/.local/lib/python3.10/site-packages (from haystack-ai) (6.0.1)\n",
      "Requirement already satisfied: networkx in /home/cherry/.local/lib/python3.10/site-packages (from haystack-ai) (3.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in /home/cherry/.local/lib/python3.10/site-packages (from haystack-ai) (8.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/cherry/.local/lib/python3.10/site-packages (from haystack-ai) (4.11.0)\n",
      "Requirement already satisfied: posthog in /home/cherry/.local/lib/python3.10/site-packages (from haystack-ai) (3.5.0)\n",
      "Requirement already satisfied: pandas in /home/cherry/.local/lib/python3.10/site-packages (from haystack-ai) (2.2.0)\n",
      "Requirement already satisfied: jinja2 in /home/cherry/.local/lib/python3.10/site-packages (from haystack-ai) (3.1.2)\n",
      "Collecting lazy-imports\n",
      "  Downloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: python-dateutil in /home/cherry/.local/lib/python3.10/site-packages (from haystack-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: sniffio in /home/cherry/.local/lib/python3.10/site-packages (from openai>=1.1.0->haystack-ai) (1.3.0)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m318.9/318.9 KB\u001b[0m \u001b[31m536.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->haystack-ai) (1.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/cherry/.local/lib/python3.10/site-packages (from openai>=1.1.0->haystack-ai) (2.7.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/cherry/.local/lib/python3.10/site-packages (from openai>=1.1.0->haystack-ai) (0.24.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/cherry/.local/lib/python3.10/site-packages (from openai>=1.1.0->haystack-ai) (3.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/cherry/.local/lib/python3.10/site-packages (from jinja2->haystack-ai) (2.1.5)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/cherry/.local/lib/python3.10/site-packages (from pandas->haystack-ai) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/cherry/.local/lib/python3.10/site-packages (from pandas->haystack-ai) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /home/cherry/.local/lib/python3.10/site-packages (from python-dateutil->haystack-ai) (1.16.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/cherry/.local/lib/python3.10/site-packages (from posthog->haystack-ai) (2.2.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /usr/lib/python3/dist-packages (from posthog->haystack-ai) (1.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/cherry/.local/lib/python3.10/site-packages (from requests->haystack-ai) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cherry/.local/lib/python3.10/site-packages (from requests->haystack-ai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/cherry/.local/lib/python3.10/site-packages (from requests->haystack-ai) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/cherry/.local/lib/python3.10/site-packages (from requests->haystack-ai) (2024.2.2)\n",
      "Requirement already satisfied: exceptiongroup in /home/cherry/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->haystack-ai) (1.1.0)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /home/cherry/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai) (0.17.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/cherry/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/cherry/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai) (2.18.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/cherry/.local/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai) (0.14.0)\n",
      "Installing collected packages: lazy-imports, jiter, openai, haystack-experimental, haystack-ai\n",
      "Successfully installed haystack-ai-2.3.1 haystack-experimental-0.1.1 jiter-0.5.0 lazy-imports-0.3.1 openai-1.40.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install haystack-ai "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and index the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import re\n",
    "from pprint import pprint\n",
    "from ast import literal_eval\n",
    "from typing import List\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 12:17:58.056838: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-09 12:17:58.964608: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-09 12:18:01.950065: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-09 12:18:01.950263: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-09 12:18:02.273557: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-09 12:18:03.403491: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-09 12:18:03.405769: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-09 12:18:11.889019: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/cherry/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913ac3cdc147407c92a95fc6929f151b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'doc_writer': {'documents_written': 9895}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline, Document\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.utils import Secret\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.dataclasses import ChatMessage\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"product_sample.csv\")\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        content=item.product_name, \n",
    "        meta={\n",
    "            \"id\": item.uniq_id, \n",
    "            \"price\": item.selling_price, \n",
    "            \"url\": item.product_url\n",
    "        }\n",
    "    ) for item in df.itertuples()\n",
    "]\n",
    "\n",
    "indexing_pipeline = Pipeline()\n",
    "\n",
    "indexing_pipeline.add_component(\n",
    "    instance=SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"), name=\"doc_embedder\"\n",
    ")\n",
    "\n",
    "indexing_pipeline.add_component(instance=DocumentWriter(document_store=document_store), name=\"doc_writer\")\n",
    "\n",
    "indexing_pipeline.connect(\"doc_embedder.documents\", \"doc_writer.documents\")\n",
    "\n",
    "\n",
    "indexing_pipeline.run({\"doc_embedder\": {\"documents\": documents}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = lambda : OpenAIGenerator(\n",
    "    api_key=Secret.from_env_var(\"GROQ_API_KEY\"),\n",
    "    api_base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    generation_kwargs = {\"max_tokens\": 512}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_chat_generator = lambda **kwargs: OpenAIChatGenerator(\n",
    "    api_key=Secret.from_env_var(\"GROQ_API_KEY\"),\n",
    "    api_base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"llama3-groq-70b-8192-tool-use-preview\",\n",
    "    generation_kwargs={\"max_tokens\": 512},\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the query analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7350e19d89d0>\n",
       "üöÖ Components\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "üõ§Ô∏è Connections\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Understand the user query and list of products the user is interested in and return product names as list.\n",
    "You should always return a Python list. Do not return any explanation.\n",
    "\n",
    "Examples:\n",
    "Question: I am interested in camping boots, charcoal and disposable rain jacket.\n",
    "Answer: [\"camping_boots\",\"charcoal\",\"disposable_rain_jacket\"]\n",
    "\n",
    "Question: Need a laptop, wireless mouse, and noise-cancelling headphones for work.\n",
    "Answer: [\"laptop\",\"wireless_mouse\",\"noise_cancelling_headphones\"]\n",
    "\n",
    "Question: {{ question }}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "product_identifier = Pipeline()\n",
    "\n",
    "product_identifier.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "product_identifier.add_component(\"llm\", generator())\n",
    "\n",
    "product_identifier.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7350e19d82e0>\n",
       "üöÖ Components\n",
       "  - embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "üõ§Ô∏è Connections\n",
       "  - embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Return product name, price, and url as a python dictionary. \n",
    "You should always return a Python dictionary with keys price, name and url for single product.\n",
    "You should always return a Python list of dictionaries with keys price, name and url for multiple products.\n",
    "Do not return any explanation.\n",
    "\n",
    "Legitimate Response Schema:\n",
    "{\"price\": \"float\", \"name\": \"string\", \"url\": \"string\"}\n",
    "Legitimate Response Schema for multiple products:\n",
    "[{\"price\": \"float\", \"name\": \"string\", \"url\": \"string\"},{\"price\": \"float\", \"name\": \"string\", \"url\": \"string\"}]\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    product_price: {{ document.meta['price'] }}\n",
    "    product_url: {{ document.meta['url'] }}\n",
    "    product_id: {{ document.meta['id'] }}\n",
    "    product_name: {{ document.content }}\n",
    "{% endfor %}\n",
    "Question: {{ question }}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "rag_pipe = Pipeline()\n",
    "rag_pipe.add_component(\"embedder\", SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "rag_pipe.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=document_store, top_k=5))\n",
    "rag_pipe.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "rag_pipe.add_component(\"llm\", generator())\n",
    "\n",
    "rag_pipe.connect(\"embedder.embedding\", \"retriever.query_embedding\")\n",
    "rag_pipe.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipe.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product Identifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_identifier_func(query: str):\n",
    "    \"\"\"\n",
    "    Identifies products based on a given query and retrieves relevant details for each identified product.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The query string used to identify products.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where the keys are product names and the values are details of each product. If no products are found, returns \"No product found\".\n",
    "    \"\"\"\n",
    "    product_understanding = product_identifier.run({\"prompt_builder\": {\"question\": query}})\n",
    "\n",
    "    try:\n",
    "        product_list = literal_eval(product_understanding[\"llm\"][\"replies\"][0])\n",
    "    except:\n",
    "        return \"No product found\"\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for product in product_list:\n",
    "        response = rag_pipe.run({\"embedder\": {\"text\": product}, \"prompt_builder\": {\"question\": product}})\n",
    "        try:\n",
    "            results[product] = literal_eval(response[\"llm\"][\"replies\"][0])\n",
    "        except:\n",
    "            results[product] = {}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67619b240de44be492b80f4e86136820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c835e56f2d148a4ba64b1689fe22e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'crossbow': [{'price': 23.78,\n",
       "   'name': 'Zing Air ZX Crossbow in FFP, Orange',\n",
       "   'url': 'https://www.amazon.com/Zing-Air-Crossbow-FFP-Orange/dp/B00GH5JOLS'},\n",
       "  {'price': 237.68,\n",
       "   'name': 'DB Longboards CoreFlex Crossbow 41\" Bamboo Fiberglass Longboard Complete',\n",
       "   'url': 'https://www.amazon.com/DB-Longboards-CoreFlex-Fiberglass-Longboard/dp/B07KMVJJK7'}],\n",
       " 'woodstock_puzzle': [{'price': 17.49,\n",
       "   'name': 'Woodstock- Collage 500 pc Puzzle',\n",
       "   'url': 'https://www.amazon.com/Woodstock-Collage-500-pc-Puzzle/dp/B07MX21WWX'}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I want crossbow and woodstock puzzle\"\n",
    "\n",
    "product_identifier_func(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our budget-friendly function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_budget_friendly_option(selected_product_details):\n",
    "    \"\"\"\n",
    "    Finds the most budget-friendly option for each category of products.\n",
    "\n",
    "    Parameters:\n",
    "    selected_product_details (dict): A dictionary where the keys are product categories and the values are lists of product details. Each product detail is expected to be a dictionary containing a 'price' key.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where the keys are product categories and the values are the most budget-friendly product details for each category.\n",
    "    \"\"\"\n",
    "    budget_friendly_options = {}\n",
    "    \n",
    "    for category, items in selected_product_details.items():\n",
    "        if isinstance(items, list):\n",
    "            lowest_price_item = min(items, key=lambda x: x['price'])\n",
    "        else:\n",
    "            lowest_price_item = items\n",
    "        \n",
    "        budget_friendly_options[category] = lowest_price_item\n",
    "    \n",
    "    return budget_friendly_options\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = '''<|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags. You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>\n",
    "{\"name\": <function-name>,\"arguments\": <args-dict>}\n",
    "</tool_call>\n",
    "\n",
    "Here are the available tools:\n",
    "<tools>\n",
    "    {\n",
    "        \"name\": \"product_identifier_func\",\n",
    "        \"description\": \"To understand user interested products and its details\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The query to use in the search. Infer this from the user's message. It should be a question or a statement\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"find_budget_friendly_option\",\n",
    "        \"description\": \"Get the most cost-friendly option. If selected_product_details has morethan one key this should return most cost-friendly options\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"selected_product_details\": {\n",
    "                    \"type\": \"dict\",\n",
    "                    \"description\": \"Input data is a dictionary where each key is a category name, and its value is either a single dictionary with 'price', 'name', and 'url' keys or a list of such dictionaries; example: {'category1': [{'price': 10.5, 'name': 'item1', 'url': 'http://example.com/item1'}, {'price': 8.99, 'name': 'item2', 'url': 'http://example.com/item2'}], 'category2': {'price': 15.0, 'name': 'item3', 'url': 'http://example.com/item3'}}\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"selected_product_details\"]\n",
    "        }\n",
    "    }\n",
    "</tools><|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "I need to buy a crossbow<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "<tool_call>\n",
    "{\"id\":\"call_deok\",\"name\":\"product_identifier_func\",\"arguments\":{\"query\":\"I need to buy a crossbow\"}}\n",
    "</tool_call><|eot_id|><|start_header_id|>tool<|end_header_id|>\n",
    "\n",
    "<tool_response>\n",
    "{\"id\":\"call_deok\",\"result\":{'crossbow': {'price': 237.68,'name': 'crossbow','url': 'https://www.amazon.com/crossbow/dp/B07KMVJJK7'}}}\n",
    "</tool_response><|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'replies': [ChatMessage(content='<tool_call>\\n'\n",
      "                                 '{\"id\": 0, \"name\": \"product_identifier_func\", '\n",
      "                                 '\"arguments\": {\"query\": \"I need to buy a '\n",
      "                                 'crossbow for my child\"}}\\n'\n",
      "                                 '</tool_call>\\n'\n",
      "                                 '<tool_call>\\n'\n",
      "                                 '{\"id\": 1, \"name\": \"product_identifier_func\", '\n",
      "                                 '\"arguments\": {\"query\": \"I need to buy a '\n",
      "                                 'Pokemon for myself\"}}\\n'\n",
      "                                 '</tool_call>',\n",
      "                         role=<ChatRole.ASSISTANT: 'assistant'>,\n",
      "                         name=None,\n",
      "                         meta={'finish_reason': 'stop',\n",
      "                               'index': 0,\n",
      "                               'model': 'llama3-groq-70b-8192-tool-use-preview',\n",
      "                               'usage': {'completion_time': 0.216826208,\n",
      "                                         'completion_tokens': 70,\n",
      "                                         'prompt_time': 0.043703714,\n",
      "                                         'prompt_tokens': 561,\n",
      "                                         'total_time': 0.26052992199999997,\n",
      "                                         'total_tokens': 631}})]}\n"
     ]
    }
   ],
   "source": [
    "## Testing agent\n",
    "messages = [\n",
    "    ChatMessage.from_system(\n",
    "        chat_template\n",
    "    ),\n",
    "    ChatMessage.from_user(\"I need to buy a crossbow for my child and Pok√©mon for myself.\"),\n",
    "]\n",
    "\n",
    "chat_generator = get_chat_generator()\n",
    "response = chat_generator.run(messages=messages)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tool_calls(tool_calls_str):\n",
    "    json_objects = re.findall(r'<tool_call>(.*?)</tool_call>', tool_calls_str, re.DOTALL)\n",
    "    \n",
    "    result_list = [json.loads(obj) for obj in json_objects]\n",
    "    \n",
    "    return result_list\n",
    "\n",
    "available_functions = {\n",
    "    \"product_identifier_func\": product_identifier_func, \n",
    "    \"find_budget_friendly_option\": find_budget_friendly_option\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gradio\n",
      "  Downloading gradio-4.41.0-py3-none-any.whl (12.6 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (6.0.1)\n",
      "Collecting tomlkit==0.12.0\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: urllib3~=2.0 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (2.2.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (3.1.2)\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (10.3.0)\n",
      "Collecting aiofiles<24.0,>=22.0\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: packaging in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (3.9.0)\n",
      "Collecting ffmpy\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (0.30.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (3.7.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (0.0.9)\n",
      "Collecting semantic-version~=2.0\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (3.10.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (0.12.3)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: fastapi in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (0.111.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (0.24.1)\n",
      "Collecting ruff>=0.2.2\n",
      "  Downloading ruff-0.5.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic>=2.0 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (2.7.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (0.23.2)\n",
      "Collecting gradio-client==1.3.0\n",
      "  Downloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m318.7/318.7 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0,>=1.0 in /home/cherry/.local/lib/python3.10/site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: fsspec in /home/cherry/.local/lib/python3.10/site-packages (from gradio-client==1.3.0->gradio) (2023.6.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /home/cherry/.local/lib/python3.10/site-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/cherry/.local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/cherry/.local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.1.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/cherry/.local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.6)\n",
      "Requirement already satisfied: certifi in /home/cherry/.local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /home/cherry/.local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (0.17.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/cherry/.local/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
      "Requirement already satisfied: requests in /home/cherry/.local/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: filelock in /home/cherry/.local/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/cherry/.local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/cherry/.local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/cherry/.local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/cherry/.local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/cherry/.local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/cherry/.local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/cherry/.local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/cherry/.local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/cherry/.local/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/cherry/.local/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/cherry/.local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/cherry/.local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.7.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/cherry/.local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /home/cherry/.local/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /home/cherry/.local/lib/python3.10/site-packages (from fastapi->gradio) (0.37.2)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /home/cherry/.local/lib/python3.10/site-packages (from fastapi->gradio) (2.1.1)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /home/cherry/.local/lib/python3.10/site-packages (from fastapi->gradio) (5.10.0)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /home/cherry/.local/lib/python3.10/site-packages (from fastapi->gradio) (0.0.4)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /home/cherry/.local/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/cherry/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/cherry/.local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/cherry/.local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/cherry/.local/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/cherry/.local/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/cherry/.local/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.22.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/cherry/.local/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cherry/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/cherry/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Installing collected packages: pydub, tomlkit, semantic-version, ruff, ffmpy, aiofiles, gradio-client, gradio\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "poetry 1.1.12 requires keyring<22.0.0,>=21.2.0; python_version >= \"3.6\" and python_version < \"4.0\", but you have keyring 23.5.0 which is incompatible.\n",
      "poetry 1.1.12 requires packaging<21.0,>=20.4, but you have packaging 23.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiofiles-23.2.1 ffmpy-0.4.0 gradio-4.41.0 gradio-client-1.3.0 pydub-0.25.1 ruff-0.5.7 semantic-version-2.10.0 tomlkit-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a065663d50f04f3fad54c4ef114e52a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "messages = [ChatMessage.from_system(chat_template)]\n",
    "chat_generator = get_chat_generator()\n",
    "\n",
    "def chatbot_with_fc(message, messages):\n",
    "    messages.append(ChatMessage.from_user(message))\n",
    "    response = chat_generator.run(messages=messages)\n",
    "\n",
    "    while True:\n",
    "        if response and \"<tool_call>\" in response[\"replies\"][0].content:\n",
    "            function_calls = extract_tool_calls(response[\"replies\"][0].content)\n",
    "            for function_call in function_calls:\n",
    "\n",
    "                function_name = function_call[\"name\"]\n",
    "                function_args = function_call[\"arguments\"]\n",
    "\n",
    "                function_to_call = available_functions[function_name]\n",
    "                function_response = function_to_call(**function_args)\n",
    "\n",
    "                messages.append(ChatMessage.from_function(content=json.dumps(function_response), name=function_name))\n",
    "                response = chat_generator.run(messages=messages)\n",
    "\n",
    "        else:\n",
    "            messages.append(response[\"replies\"][0])\n",
    "            break\n",
    "    return response[\"replies\"][0].content\n",
    "\n",
    "\n",
    "def chatbot_interface(user_input, state):\n",
    "    response_content = chatbot_with_fc(user_input, state)\n",
    "    return response_content, state\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# AI Purchase Assistant\")\n",
    "    gr.Markdown(\"Ask me about products you want to buy!\")\n",
    "    \n",
    "    state = gr.State(value=messages)\n",
    "    \n",
    "    with gr.Row():\n",
    "        user_input = gr.Textbox(label=\"Your message:\")\n",
    "        response_output = gr.Markdown(label=\"Response:\")\n",
    "    \n",
    "    user_input.submit(chatbot_interface, [user_input, state], [response_output, state])\n",
    "    gr.Button(\"Send\").click(chatbot_interface, [user_input, state], [response_output, state])\n",
    "\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
